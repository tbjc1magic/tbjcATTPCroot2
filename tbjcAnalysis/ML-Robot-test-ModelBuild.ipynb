{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: /afs/crc.nd.edu/user/j/jlai1/.local/lib/python2.7/site-packages/pandas/_libs/tslib.so: undefined symbol: PyUnicodeUCS2_FromStringAndSize not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-76d892a3c54a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/user/j/jlai1/.local/lib/python2.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                       \u001b[0;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                       \u001b[0;34m\"'python setup.py build_ext --inplace --force' to build \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                       \"the C extensions first.\".format(module))\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: C extension: /afs/crc.nd.edu/user/j/jlai1/.local/lib/python2.7/site-packages/pandas/_libs/tslib.so: undefined symbol: PyUnicodeUCS2_FromStringAndSize not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "from sqlalchemy import *\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import newton\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "import peakutils\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from IPython import display\n",
    "%matplotlib inline \n",
    "\n",
    "########### plot.ly #########\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import iplot,plot\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### gaussian wave ############\n",
    "\n",
    "def GenerateGaussianPulse(width, mean, height, sigma):\n",
    "    def Gaussian(x, mean, height_, sigma):        \n",
    "        return height_*np.exp(-(x-mean)*(x-mean)/(2*float(sigma)*float(sigma)))\n",
    "    \n",
    "    xx = np.array(range(width))\n",
    "    return Gaussian(xx, mean, height, sigma)\n",
    "\n",
    "\n",
    "def Generate1GaussianPulse(width,height,sigma):\n",
    "    gap = 50\n",
    "    sigma_ = random.uniform( 0.1*sigma,sigma*2)\n",
    "    mean = random.uniform(gap, width-gap)\n",
    "    height_ = random.uniform(height*0.2,height*3)\n",
    "    return GenerateGaussianPulse(width, mean, height_, sigma_), sigma_\n",
    "    \n",
    "def GenerateGaussianData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1GaussianPulse(512, 20,20)\n",
    "        data.append(x) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "#plt.plot(GenerateGaussianData(10)[0].T);\n",
    "\n",
    "#### square wave ##########\n",
    "\n",
    "def Generate1SquareWave(width, start, end, height, conv):\n",
    "    xx = np.array(range(width))\n",
    "    yy = np.logical_and(xx>start, xx<end)*height\n",
    "    return np.convolve((range(conv)+range(conv)[::-1])[::-1],yy,'SAME')/float(sum(range(conv)))/2.0\n",
    "\n",
    "def Generate1SquareData(width,height,conv):\n",
    "    gap = 50\n",
    "    start = random.uniform(gap,width-gap*3)\n",
    "    end = random.uniform(start+gap,width-gap)\n",
    "    \n",
    "    height_ = random.uniform(height*0.2,height*3)\n",
    "    return Generate1SquareWave(width,start,end,height_,conv),end-start\n",
    "\n",
    "def GenerateSquareData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1SquareData(512, 10,20)\n",
    "        data.append(x) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "\n",
    "######### noisy gaussian ########\n",
    "def GenerateNoisyGaussianData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1GaussianPulse(512, 50,20)\n",
    "        data.append(x+np.random.normal(0, 1.5, size=512)) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "\n",
    "######### noisy gaussian ########\n",
    "def GenerateNoisyGaussianData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1GaussianPulse(512, 50,20)\n",
    "        data.append(x+np.random.normal(0, 1.5, size=512)) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "\n",
    "######### noisy square wave ########\n",
    "def GenerateNoisySquareData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1SquareData(512, 50,20)\n",
    "        data.append(x+np.random.normal(0, 2, size=512)) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "\n",
    "\n",
    "######### spiky noise ##############\n",
    "\n",
    "def SpikeWave(mean, sigma, height):\n",
    "    epsilon =1e1\n",
    "    x = np.array(range(512))\n",
    "    return height/(1+np.power(x-mean,4)/float(sigma)/float(sigma))\n",
    "    \n",
    "\n",
    "\n",
    "######### noisy square wave ########\n",
    "def GenerateSpikyNoisySquareData(size):\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(size):\n",
    "        x,y = Generate1SquareData(512, 50,20)\n",
    "        \n",
    "        SpikeMean = random.uniform(50,450)\n",
    "        SpikeSTD = random.uniform(2,20)\n",
    "        SpikeH = random.uniform(10,100)\n",
    "        \n",
    "        SpikeNoise = np.array([0 for _ in range(512)])\n",
    "        \n",
    "        \n",
    "        data.append(x+np.random.normal(0, 2, size=512)+SpikeWave(SpikeMean,SpikeSTD,SpikeH)) \n",
    "        label.append(y)\n",
    "\n",
    "    return np.array(data),np.array(label)\n",
    "\n",
    "####################################\n",
    "\n",
    "#plt.plot(Spike(100,50,100))\n",
    "def Normalizer(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        x,y = f(*args, **kwargs)\n",
    "        return x/np.max(x,axis=1).astype(float)[:,None],y\n",
    "        \n",
    "    return wrapper\n",
    "    \n",
    "\n",
    "GenerateData = Normalizer(GenerateSpikyNoisySquareData)\n",
    "plt.plot(GenerateData(30)[0].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(y_,y):\n",
    "    return 1-np.sum(np.sqrt((y_-y)*(y_-y)))/np.sum(np.abs(y))\n",
    "\n",
    "\n",
    "optimizer, prediction = None, None\n",
    "def train(hidden=[200],training_rate = 0.0001,decay_rate = 0.96, batchSize = 30,testSzie = 100,\n",
    "         trainingLoops = 10000):\n",
    "    optimizer, prediction = None, None\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        FN=512\n",
    "        yd = 1\n",
    "        x = tf.placeholder(tf.float32,[None, FN])\n",
    "        y = tf.placeholder(tf.float32,[None, yd])\n",
    "  \n",
    "        bs = []\n",
    "        Ws = []\n",
    "        \n",
    "        pre = FN\n",
    "        \n",
    "        for idx, s in enumerate(hidden):\n",
    "            W = tf.get_variable(\"W\"+str(idx), shape=[pre,s],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.zeros([s]))\n",
    "            pre = s\n",
    "            Ws.append(W)\n",
    "            bs.append(b)     \n",
    "        \n",
    "        W = tf.get_variable(\"Wy\", shape=[pre,yd],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.Variable(tf.zeros([yd]))\n",
    "        Ws.append(W)\n",
    "        bs.append(b)          \n",
    "\n",
    "        pre = x\n",
    "        for W,b in zip(Ws[:-1],bs[:-1]):\n",
    "            pre = tf.nn.relu(tf.matmul(pre,W) + b)\n",
    "            #pre = tf.nn.dropout(pre,0.8)\n",
    "        \n",
    "        logits = tf.matmul(pre,Ws[-1])+bs[-1]\n",
    "\n",
    "        loss = tf.reduce_mean(tf.square(logits-y)) \n",
    "\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(training_rate).minimize(loss)\n",
    "        optimizer = tf.train.AdamOptimizer(training_rate).minimize(loss)\n",
    "        prediction = logits\n",
    " \n",
    " \n",
    "    ac = []\n",
    "    st =[]\n",
    "    lo = []\n",
    "    r_previous = None\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print('Initialized')\n",
    "        for j in range(trainingLoops):\n",
    " \n",
    "            x_,y_ = GenerateData(batchSize)\n",
    "            #print x_.shape\n",
    "            feed_dict = {x:x_,y:y_[:,None]}\n",
    "            _, l, predict = session.run([optimizer,loss, prediction], feed_dict=feed_dict)\n",
    "            if j %1000 == 0:\n",
    "                acc = accuracy(predict.flatten(),y_)\n",
    "                st.append(j)\n",
    "                ac.append(acc)\n",
    "                lo.append(l)\n",
    "                plt.subplot(2,1,1)\n",
    "                plt.plot(st[1:],ac[1:],'r',label='accuracy')\n",
    "                plt.legend()\n",
    "                plt.subplot(2,1,2)\n",
    "                plt.plot(st[1:],lo[1:],'b',label='loss')\n",
    "                plt.legend()\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(plt.gcf())\n",
    "                plt.clf()\n",
    "                print \"step {} prediction: {}; the loss {}; std:{}\".format(j,acc,l,np.std(predict.flatten()))\n",
    "\n",
    "                time.sleep(0.1)\n",
    " \n",
    "                \n",
    "        x_,y_ = GenerateData(testSzie)\n",
    "        feed_dict = {x:x_,y:y_[:,None]}\n",
    "        predict = session.run( prediction, feed_dict=feed_dict)\n",
    "        print \"test accuracy {:.2f}%\".format(accuracy(predict.flatten(),y_)*100)\n",
    "        \n",
    "        for a,b in zip(predict.flatten(),y_):\n",
    "            print a,b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(hidden=[512,200,100,50,10],training_rate=1e-5, batchSize = 100,testSzie = 100,trainingLoops = 30000)\n",
    "#train(hidden=[200,10],training_rate=1e-5, batchSize = 100,testSzie = 100,trainingLoops = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = GenerateData(100)\n",
    "print accuracy(y,y[:,None].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_,y_ = GenerateData(sub,fd_df,100)\n",
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "base\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "class tbjcBase():\n",
    "    def __init__(self):\n",
    "        print \"init base\"\n",
    "    \n",
    "    def test(self):\n",
    "        print \"base\"\n",
    "\n",
    "class tbjcModel(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            FN=512\n",
    "            yd = 1\n",
    "            x = tf.placeholder(tf.float32,[None, FN])\n",
    "            y = tf.placeholder(tf.float32,[None, yd])\n",
    "\n",
    "            bs = []\n",
    "            Ws = []\n",
    "\n",
    "            pre = FN\n",
    "\n",
    "            for idx, s in enumerate(hidden):\n",
    "                W = tf.get_variable(\"W\"+str(idx), shape=[pre,s],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.Variable(tf.zeros([s]))\n",
    "                pre = s\n",
    "                Ws.append(W)\n",
    "                bs.append(b)     \n",
    "\n",
    "            W = tf.get_variable(\"Wy\", shape=[pre,yd],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.zeros([yd]))\n",
    "            Ws.append(W)\n",
    "            bs.append(b)          \n",
    "\n",
    "            pre = x\n",
    "            for W,b in zip(Ws[:-1],bs[:-1]):\n",
    "                pre = tf.nn.relu(tf.matmul(pre,W) + b)\n",
    "                #pre = tf.nn.dropout(pre,0.8)\n",
    "\n",
    "            logits = tf.matmul(pre,Ws[-1])+bs[-1]\n",
    "\n",
    "            loss = tf.reduce_mean(tf.square(logits-y)) \n",
    "\n",
    "            #optimizer = tf.train.GradientDescentOptimizer(training_rate).minimize(loss)\n",
    "            self.optimizer = tf.train.AdamOptimizer(training_rate).minimize(loss)\n",
    "            self.prediction = logits\n",
    "    \n",
    "    def fit(x,y):\n",
    " \n",
    "        \n",
    "    \n",
    "    def test(self):\n",
    "        super(tbjcModel,self).test()\n",
    "        #tbjcBase.test(self)\n",
    "        print \"test\"\n",
    "        \n",
    "tbjc = tbjcModel()\n",
    "tbjc.test()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
